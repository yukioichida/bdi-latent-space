{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23110\n"
     ]
    },
    {
     "data": {
      "text/plain": "BeliefAutoencoder(\n  (drop): Dropout(p=0.0, inplace=False)\n  (embedding): Embedding(1450, 128, padding_idx=0)\n  (lstm_encoder): GRU(128, 512, batch_first=True, bidirectional=True)\n  (sampling_input): Linear(in_features=1024, out_features=32, bias=True)\n  (z_embedding): Linear(in_features=32, out_features=128, bias=True)\n  (lstm_decoder): GRU(128, 512, batch_first=True)\n  (output_layer): Linear(in_features=512, out_features=1450, bias=True)\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "from sources.model import BeliefAutoencoder, gumbel_softmax\n",
    "from sources.preprocessing import preprocessing, preprocess_sentence\n",
    "\n",
    "def set_seed(seed=20190827):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "set_seed()\n",
    "\n",
    "preprocessed_data = preprocessing(\"data/dataset_sentence_level.csv\", device='cpu')\n",
    "vocab = preprocessed_data.vocab\n",
    "model = BeliefAutoencoder(emb_dim=128, h_dim=512, latent_dim=16, vocab=vocab, categorical_dim=2, activation='gumbel')\n",
    "\n",
    "#model.load_state_dict(torch.load(\"models/belief-autoencoder-bc-YP68fCFu.pth\", map_location='cpu'))\n",
    "#model.load_state_dict(torch.load(\"models/belief-autoencoder-gumbel-128-512-32-FatzuhGa.pth\", map_location='cpu'))\n",
    "model.load_state_dict(torch.load(\"models/belief-autoencoder-bc-128-512-32-dvmEhYqV.pth\", map_location='cpu'))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 1,  3,  4, 18, 48, 15, 16, 17,  0],\n        [ 1,  3,  4,  5,  6, 15, 16, 17,  0]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"you have an orange in your inventory\", \"you have a stopwatch in your inventory\"]\n",
    "seq_lens = [len(s.split()) for s in sentences]\n",
    "max_len = max(seq_lens)\n",
    "vectorized = []\n",
    "for s in sentences:\n",
    "    idxs, tgt, seq_len = preprocess_sentence(s, vocab, max_len)\n",
    "    vectorized.append(idxs)\n",
    "tensorized = torch.tensor(vectorized)\n",
    "\n",
    "seq_len = torch.tensor(seq_lens)\n",
    "tensorized"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ichida/miniconda3/envs/dl/lib/python3.9/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[0., 0.],\n         [1., 0.],\n         [1., 0.],\n         [1., 1.],\n         [1., 1.],\n         [0., 1.],\n         [1., 0.],\n         [1., 1.],\n         [0., 1.],\n         [0., 1.],\n         [1., 0.],\n         [1., 1.],\n         [0., 0.],\n         [0., 1.],\n         [1., 1.],\n         [1., 0.]],\n\n        [[1., 0.],\n         [1., 0.],\n         [0., 0.],\n         [1., 1.],\n         [1., 1.],\n         [0., 1.],\n         [1., 1.],\n         [1., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [1., 1.],\n         [1., 1.],\n         [0., 1.],\n         [1., 1.],\n         [1., 0.]]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_hat, qy, _ = model(x=tensorized, seq_len=seq_len, temperature=0.5)\n",
    "#qy = gumbel_softmax(qy, temperature=1e-20,latent_dim=30, categorical_dim=2, hard=True)\n",
    "qy_sig = F.sigmoid(qy)\n",
    "torch.round(qy_sig).squeeze(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "latent = torch.round(qy_sig).squeeze(-1)\n",
    "latent = latent.view(2, 1, 32)\n",
    "latent_vectors = latent.detach().cpu().numpy()\n",
    "for vector in latent_vectors:\n",
    "    plt.figure()\n",
    "    plt.imshow(vector, cmap='gray')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'have', 'a', 'orange', 'in', 'your', 'inventory', '<EOS>', 'agent']\n",
      "[ 5  4  5 48 15 16 17  2 79]\n",
      "['a', 'have', 'a', 'stopwatch', 'which', 'your', 'inventory', '<EOS>', 'agent']\n",
      "[ 5  4  5  6  7 16 17  2 79]\n"
     ]
    }
   ],
   "source": [
    "inverted_vocab = {idx: word for word, idx in vocab.items()}\n",
    "\n",
    "y_hat.argmax(dim=-1)\n",
    "idxs = y_hat.argmax(dim=-1).detach().cpu().numpy()\n",
    "#idx = model.inference(qy, 20)\n",
    "for idx in idxs:\n",
    "    print([inverted_vocab[i] for i in idx])\n",
    "    print(idx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 60]' is invalid for input of size 32",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [20], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m next_word \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([vocab[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m<SOS>\u001B[39m\u001B[38;5;124m'\u001B[39m]])\n\u001B[0;32m----> 2\u001B[0m z_emb \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mz_embedding(\u001B[43mqy\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m)\u001B[49m)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)  \u001B[38;5;66;03m# z_emb será usado como h inicial do LSTM decoder\u001B[39;00m\n\u001B[1;32m      4\u001B[0m _, batch_size, hidden_len \u001B[38;5;241m=\u001B[39m z_emb\u001B[38;5;241m.\u001B[39msize()\n\u001B[1;32m      5\u001B[0m hidden \u001B[38;5;241m=\u001B[39m z_emb\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mint\u001B[39m(hidden_len \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m))  \u001B[38;5;66;03m# h_t\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: shape '[1, 60]' is invalid for input of size 32"
     ]
    }
   ],
   "source": [
    "next_word = torch.tensor([vocab['<SOS>']])\n",
    "z_emb = model.z_embedding(qy[0,:,:].view(1, 60)).unsqueeze(0)  # z_emb será usado como h inicial do LSTM decoder\n",
    "\n",
    "_, batch_size, hidden_len = z_emb.size()\n",
    "hidden = z_emb.view(2, 1, int(hidden_len / 2))  # h_t\n",
    "sentence = []\n",
    "next_word = next_word.unsqueeze(0)\n",
    "print(hidden.size(), next_word.size())\n",
    "for i in range(max_len):\n",
    "    sentence.append(next_word)\n",
    "    next_word_emb = model.embedding(next_word)\n",
    "    x, hidden = model.lstm_decoder(next_word_emb, hidden)\n",
    "    #x, _ = pad_packed_sequence(x)\n",
    "    x = model.output_layer(x)\n",
    "    next_word = x.argmax(dim=-1)\n",
    "s = torch.cat(sentence)\n",
    "s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "['<SOS>', '<PAD>', '<PAD>', '<PAD>', '3', '<PAD>', '<PAD>']"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[inverted_vocab[i] for i in s.squeeze(-1).detach().numpy().tolist()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[8.2806e-04, 9.9941e-01],\n         [6.5952e-01, 3.7537e-01],\n         [1.3543e-02, 9.8676e-01],\n         [7.6780e-02, 9.3148e-01],\n         [9.9985e-01, 1.1610e-04],\n         [9.9946e-01, 2.8733e-04],\n         [9.9685e-01, 6.6426e-03],\n         [9.9788e-01, 5.5238e-03],\n         [9.9924e-01, 6.1472e-04],\n         [9.9751e-05, 9.9984e-01],\n         [7.9383e-07, 1.0000e+00],\n         [2.1500e-01, 7.1328e-01],\n         [9.1362e-03, 9.8036e-01],\n         [8.4709e-06, 9.9998e-01],\n         [9.5656e-01, 5.3405e-02],\n         [2.4508e-02, 9.5849e-01],\n         [1.8293e-02, 9.8606e-01],\n         [9.7044e-01, 1.9000e-02],\n         [8.6453e-02, 8.4050e-01],\n         [9.9999e-01, 1.7152e-05],\n         [4.0549e-02, 9.8730e-01],\n         [1.0000e+00, 3.3609e-07],\n         [1.2495e-02, 9.7839e-01],\n         [2.1059e-01, 7.9157e-01],\n         [3.6606e-05, 9.9985e-01],\n         [1.0368e-04, 9.9987e-01],\n         [8.2068e-03, 9.9318e-01],\n         [1.0000e+00, 5.1429e-07],\n         [1.1812e-06, 1.0000e+00],\n         [7.9596e-01, 1.5260e-01]]),\n tensor([[0.0314, 0.9670],\n         [0.9863, 0.0138],\n         [0.6176, 0.4158],\n         [0.6613, 0.2586],\n         [0.0011, 0.9990],\n         [0.9964, 0.0035],\n         [0.2040, 0.8675],\n         [0.6814, 0.2242],\n         [0.9967, 0.0034],\n         [0.3212, 0.5846],\n         [0.5895, 0.3386],\n         [0.0951, 0.8887],\n         [0.4411, 0.4725],\n         [0.9933, 0.0101],\n         [0.2036, 0.7176],\n         [0.5863, 0.3589],\n         [0.0013, 0.9988],\n         [0.8324, 0.1257],\n         [0.6578, 0.4205],\n         [0.9878, 0.0085],\n         [0.0479, 0.9585],\n         [0.9961, 0.0040],\n         [0.0358, 0.9769],\n         [0.1588, 0.9025],\n         [0.6934, 0.2413],\n         [0.0294, 0.9771],\n         [0.8337, 0.1701],\n         [0.0449, 0.9365],\n         [0.1169, 0.9013],\n         [0.3528, 0.3961]]))"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qy[0,:,:], qy[1,:,:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}