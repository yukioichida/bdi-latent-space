{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-09-22T06:58:47.622633Z",
     "end_time": "2023-09-22T06:58:48.459762Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import itertools\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build a matrix of sentence combinations\n",
    "\n",
    "In the BDI architecture, in order to select a plan to execute in the environment, the agent needs to check whether its context is entailed by the agent's belief base.\n",
    "Formally, given a set of beliefs $B$ and a set of contexts $C$, the expression $\\bigwedge_{c_i \\in C}\\bigvee_{b_j \\in \\mathcal{B}} b_j \\models c_i$ must be true.\n",
    "\n",
    "Since our work deals in natural language representations, we create a matrix with all combinations between all sentences contained in the belief base with all plan context sentences.\n",
    "Specifically, given a set of natural language sentences representing the belief base $B$ and another sentence set representing the context $C$, the inference operation executes the cartesian product $C \\times B = \\{(c, b) | c \\in C \\wedge b \\in B\\}$ to formulate all pairs of $(c, b)$ as input of the natural language inference model.\n",
    "In our approach, we follow the $\\bigwedge_{c_i \\in C}\\bigvee_{b_j \\in \\mathcal{B}} b_j \\models c_i$ expression and generate the cartesian product as context-wise."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinations = 6\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('you are in the kitchen', 'This room is called the kitchen.'),\n ('you are in the kitchen',\n  'You see a cupboard. The cupboard door is closed.'),\n ('you are in the kitchen', 'You see a freezer. The freezer door is closed.'),\n ('you see a closed cupboard', 'This room is called the kitchen.'),\n ('you see a closed cupboard',\n  'You see a cupboard. The cupboard door is closed.'),\n ('you see a closed cupboard',\n  'You see a freezer. The freezer door is closed.')]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beliefs = ['This room is called the kitchen.', 'You see a cupboard. The cupboard door is closed.', 'You see a freezer. The freezer door is closed.']\n",
    "\n",
    "context = ['you are in the kitchen', 'you see a closed cupboard']\n",
    "\n",
    "num_ctx_statements = len(context)\n",
    "num_beliefs = len(beliefs)\n",
    "#\n",
    "\n",
    "all_sentence_pairs = list(itertools.product(context, beliefs))\n",
    "all_sentence_pairs.sort(key=lambda x: x[0])\n",
    "print(f\"Combinations = {len(all_sentence_pairs)}\")\n",
    "all_sentence_pairs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-22T08:04:31.550357Z",
     "end_time": "2023-09-22T08:04:31.556357Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "{'entailment': 0, 'neutral': 1, 'contradiction': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded 3.6675384044647217 - model cpu\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Loading Model\")\n",
    "\n",
    "max_length = 256\n",
    "\n",
    "hg_model_hub_name = \"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "#hg_model_hub_name = \"alisawuffles/roberta-large-wanli\"\n",
    "config = AutoConfig.from_pretrained(hg_model_hub_name)\n",
    "entailment_idx = config.label2id['entailment']\n",
    "\n",
    "config = AutoConfig.from_pretrained(hg_model_hub_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(hg_model_hub_name)\n",
    "\n",
    "print(config.label2id)\n",
    "entailment_idx = config.label2id['entailment']\n",
    "\n",
    "\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(hg_model_hub_name)\n",
    "nli_model.to(device)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Model loaded {end - start} - model {nli_model.device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-22T07:56:06.223329Z",
     "end_time": "2023-09-22T07:56:09.893544Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Manipulating vectors resulted from LLM\n",
    "The next step is the application of natural language inference model for each sentence pair contained in the cartesian product $C \\times B$.\n",
    "Given a sentence pair $p$ and the NLI model represented by the function $nli$, we generate a matrix $I = \\{nli(p) | p \\in C \\times B\\}$ with all inference results.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0, 1, 1, 1, 0, 2]),\n tensor([[0.9472, 0.0512, 0.0016],\n         [0.0119, 0.9803, 0.0078],\n         [0.0051, 0.9707, 0.0242],\n         [0.0130, 0.9798, 0.0072],\n         [0.7888, 0.2086, 0.0026],\n         [0.0429, 0.1872, 0.7699]], grad_fn=<SoftmaxBackward0>))"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert into a matrix representation\n",
    "tokenized_input_seq_pair = tokenizer.batch_encode_plus(all_sentence_pairs,\n",
    "                                                                    return_token_type_ids=True, truncation=True,\n",
    "                                                                    padding=True)\n",
    "\n",
    "input_ids = torch.tensor(tokenized_input_seq_pair['input_ids'], device=device).long()\n",
    "token_type_ids = torch.tensor(tokenized_input_seq_pair['token_type_ids'], device=device).long()\n",
    "attention_mask = torch.tensor(tokenized_input_seq_pair['attention_mask'], device=device).long()\n",
    "\n",
    "# predicting NLI results\n",
    "outputs = nli_model(input_ids,\n",
    "                   attention_mask=attention_mask,\n",
    "                   token_type_ids=token_type_ids,\n",
    "                   labels=None)\n",
    "\n",
    "nli_result = outputs[0]\n",
    "probs = torch.softmax(nli_result, dim=1)\n",
    "predicted_classes = probs.argmax(-1)\n",
    "predicted_classes, probs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-22T08:04:56.984138Z",
     "end_time": "2023-09-22T08:04:57.533164Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Slicing matrix\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0 x B = Slice tensor([ True, False, False])\n",
      "c1 x B = Slice tensor([False,  True, False])\n",
      "OR operation\n"
     ]
    },
    {
     "data": {
      "text/plain": "[tensor([True]), tensor([True])]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: explicar quais linhas representam os contextos\n",
    "\n",
    "# True when a c_n is entailed by b_n\n",
    "entailment_mask = torch.where(predicted_classes == entailment_idx, True, False)\n",
    "# [B,c1:B,c2:...:B,cn]\n",
    "slice_idx = []\n",
    "idx = 0\n",
    "for i in range(num_ctx_statements):  # [c1, ..., cn]\n",
    "    slice = entailment_mask[idx:(idx + num_beliefs)]\n",
    "    slice_idx.append(slice)\n",
    "    print(f\"c{i} x B = Slice {slice}\")\n",
    "    idx = num_beliefs\n",
    "\n",
    "# True if ANY context comparation is ENTAILED by an belief in belief base (OR)\n",
    "context_or = [torch.where(c == entailment_idx, True, False).any().unsqueeze(0) for c in slice_idx]\n",
    "print(\"OR operation\")\n",
    "context_or"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-22T08:38:23.474698Z",
     "end_time": "2023-09-22T08:38:23.480894Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(True)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "or_tensor = torch.concatenate(context_or)  # at least one belief should entail a context (OR)\n",
    "and_result = or_tensor.all()  # all context must be entailed by the belief base (AND)\n",
    "and_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-22T08:05:53.620582Z",
     "end_time": "2023-09-22T08:05:53.663665Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
