{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-07-07T08:05:25.433904Z",
     "end_time": "2023-07-07T08:05:27.091039Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import itertools\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "Combinations = 6\n",
      "{'contradiction': 0, 'entailment': 1, 'neutral': 2}\n",
      "Model loaded 6.416053771972656 - model cpu\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Loading Model\")\n",
    "\n",
    "obs = ['This room is called the art studio.',\n",
    "       'you see a large cupboard. The large cupboard door is closed.',\n",
    "       'you see a table. On the table is: a glass cup (containing nothing).']\n",
    "\n",
    "context = ['You are in the art studio', 'you see a table with a container on the top containing nothing']\n",
    "\n",
    "a = list(itertools.product(obs, context))\n",
    "a.sort(key = lambda x: x[1])\n",
    "print(f\"Combinations = {len(a)}\")\n",
    "\n",
    "max_length = 256\n",
    "\n",
    "hg_model_hub_name = \"alisawuffles/roberta-large-wanli\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(hg_model_hub_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(hg_model_hub_name)\n",
    "\n",
    "print(config.label2id)\n",
    "\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device='cpu'\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(hg_model_hub_name)\n",
    "model.to(device)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Model loaded {end - start} - model {model.device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-07T08:05:29.499116Z",
     "end_time": "2023-07-07T08:05:35.969227Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.6672201156616211\n",
      "----\n",
      "Premise: This room is called the art studio.\n",
      "Hypothesis: You are in the art studio\n",
      "Entailment: 0.8970025181770325\n",
      "Neutral: 0.10274694859981537\n",
      "Contradiction: 0.0002505670709069818\n",
      "----\n",
      "Premise: you see a large cupboard. The large cupboard door is closed.\n",
      "Hypothesis: You are in the art studio\n",
      "Entailment: 0.000518354878295213\n",
      "Neutral: 0.9990247488021851\n",
      "Contradiction: 0.0004568826116155833\n",
      "----\n",
      "Premise: you see a table. On the table is: a glass cup (containing nothing).\n",
      "Hypothesis: You are in the art studio\n",
      "Entailment: 0.0004657926911022514\n",
      "Neutral: 0.9987221360206604\n",
      "Contradiction: 0.0008120540296658874\n",
      "----\n",
      "Premise: This room is called the art studio.\n",
      "Hypothesis: you see a table with a container on the top containing nothing\n",
      "Entailment: 0.0006510507664643228\n",
      "Neutral: 0.9931994080543518\n",
      "Contradiction: 0.006149493157863617\n",
      "----\n",
      "Premise: you see a large cupboard. The large cupboard door is closed.\n",
      "Hypothesis: you see a table with a container on the top containing nothing\n",
      "Entailment: 0.001431977958418429\n",
      "Neutral: 0.8691683411598206\n",
      "Contradiction: 0.12939965724945068\n",
      "----\n",
      "Premise: you see a table. On the table is: a glass cup (containing nothing).\n",
      "Hypothesis: you see a table with a container on the top containing nothing\n",
      "Entailment: 0.02068191207945347\n",
      "Neutral: 0.15828095376491547\n",
      "Contradiction: 0.8210370540618896\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tokenized_input_seq_pair = tokenizer.batch_encode_plus(a,\n",
    "                                                 max_length=max_length,\n",
    "                                                 return_token_type_ids=True, truncation=True, padding=True)\n",
    "\n",
    "input_ids = torch.tensor(tokenized_input_seq_pair['input_ids'], device=device).long()#.unsqueeze(0)\n",
    "# remember bart doesn't have 'token_type_ids', remove the line below if you are using bart.\n",
    "token_type_ids = torch.tensor(tokenized_input_seq_pair['token_type_ids'], device=device).long()#.unsqueeze(0)\n",
    "attention_mask = torch.tensor(tokenized_input_seq_pair['attention_mask'], device=device).long()#.unsqueeze(0)\n",
    "\n",
    "outputs = model(input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=None)\n",
    "# Note:\n",
    "# \"id2label\": {\n",
    "#     \"0\": \"entailment\",\n",
    "#     \"1\": \"neutral\",\n",
    "#     \"2\": \"contradiction\"\n",
    "# },\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Inference time: {end - start}\")\n",
    "logits = outputs[0]\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "for i, pair in enumerate(a):\n",
    "    predicted_probability = probs[i].tolist()  # batch_size only one\n",
    "    print('----')\n",
    "    print(\"Premise:\", pair[0])\n",
    "    print(\"Hypothesis:\", pair[1])\n",
    "    print(\"Entailment:\", predicted_probability[int(config.label2id['entailment'])])\n",
    "    print(\"Neutral:\", predicted_probability[int(config.label2id['neutral'])])\n",
    "    print(\"Contradiction:\", predicted_probability[int(config.label2id['contradiction'])])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-07T08:05:41.374171Z",
     "end_time": "2023-07-07T08:05:42.045599Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- $context = (c_1, c_2)$\n",
    "- $beliefbase = (b_1, b_2)$\n",
    "- $(b_1 \\models c_1 \\lor b_2 \\models c_1) \\land (b_1 \\models c_2 \\lor b_2 \\models c_2)$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "num_context = len(context)\n",
    "num_beliefs = len(obs)\n",
    "\n",
    "argmax_probs = probs.argmax(-1)\n",
    "c1 = argmax_probs[: num_beliefs]\n",
    "c2 = argmax_probs[num_beliefs:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-07T08:05:45.465117Z",
     "end_time": "2023-07-07T08:05:45.474149Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1, 2, 2, 2, 2, 0]), tensor([1, 2, 2]), tensor([2, 2, 0]))"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax_probs, c1, c2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-07T08:05:45.643948Z",
     "end_time": "2023-07-07T08:05:45.670893Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Not entailment\n"
     ]
    }
   ],
   "source": [
    "entailment_idx = int(config.label2id['entailment'])\n",
    "print(entailment_idx)\n",
    "if entailment_idx in c1 and entailment_idx in c2:\n",
    "    print(\"Entailment\")\n",
    "else:\n",
    "    print(\"Not entailment\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-07T08:05:47.657150Z",
     "end_time": "2023-07-07T08:05:47.665317Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ True],\n         [False],\n         [False],\n         [False],\n         [False],\n         [False]]),\n tensor([[2.5057e-04, 8.9700e-01, 1.0275e-01],\n         [4.5688e-04, 5.1835e-04, 9.9902e-01],\n         [8.1205e-04, 4.6579e-04, 9.9872e-01],\n         [6.1495e-03, 6.5105e-04, 9.9320e-01],\n         [1.2940e-01, 1.4320e-03, 8.6917e-01],\n         [8.2104e-01, 2.0682e-02, 1.5828e-01]], grad_fn=<SoftmaxBackward0>))"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment_mask = torch.where(argmax_probs == entailment_idx, True, False)\n",
    "entailment_mask.unsqueeze(1), probs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-07T08:07:59.024915Z",
     "end_time": "2023-07-07T08:07:59.072953Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.5057e-04, 8.9700e-01, 1.0275e-01],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00]], grad_fn=<MulBackward0>)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_entailment_prob = (probs * entailment_mask.unsqueeze(1))\n",
    "all_entailment_prob"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-07T08:08:11.421908Z",
     "end_time": "2023-07-07T08:08:11.471771Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.1535, grad_fn=<MeanBackward0>)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[:, entailment_idx].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-07T10:03:56.783243Z",
     "end_time": "2023-07-07T10:03:56.788244Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
