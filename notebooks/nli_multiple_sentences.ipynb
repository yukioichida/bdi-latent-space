{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-07-10T14:04:55.538022Z",
     "end_time": "2023-07-10T14:04:57.297641Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import itertools\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "Combinations = 9\n",
      "{'contradiction': 0, 'entailment': 1, 'neutral': 2}\n",
      "Model loaded 3.2141191959381104 - model cpu\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Loading Model\")\n",
    "\n",
    "# AIMA -> explicar no contexto de busca\n",
    "obs = ['This room is called the art studio.',\n",
    "       'you see a large cupboard. The large cupboard door is closed.',\n",
    "       'you see a table. On the table is: a glass cup (containing nothing).']\n",
    "\n",
    "context = ['You are in the art studio', 'you see a table with a glass cup containing nothing', 'you see a large cupboard with its door closed']\n",
    "#\n",
    "\n",
    "a = list(itertools.product(obs, context))\n",
    "a.sort(key = lambda x: x[1])\n",
    "print(f\"Combinations = {len(a)}\")\n",
    "\n",
    "max_length = 256\n",
    "\n",
    "hg_model_hub_name = \"alisawuffles/roberta-large-wanli\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(hg_model_hub_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(hg_model_hub_name)\n",
    "\n",
    "print(config.label2id)\n",
    "\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device='cpu'\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(hg_model_hub_name)\n",
    "model.to(device)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Model loaded {end - start} - model {model.device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T16:01:31.442007Z",
     "end_time": "2023-07-10T16:01:34.661981Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.label2id['entailment']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T16:10:07.939736Z",
     "end_time": "2023-07-10T16:10:07.989898Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.5921120643615723\n",
      "----\n",
      "Premise: This room is called the art studio.\n",
      "Hypothesis: You are in the art studio\n",
      "Entailment: 0.8970025181770325\n",
      "Neutral: 0.10274694859981537\n",
      "Contradiction: 0.0002505670709069818\n",
      "----\n",
      "Premise: you see a large cupboard. The large cupboard door is closed.\n",
      "Hypothesis: You are in the art studio\n",
      "Entailment: 0.000518354878295213\n",
      "Neutral: 0.9990247488021851\n",
      "Contradiction: 0.0004568826116155833\n",
      "----\n",
      "Premise: you see a table. On the table is: a glass cup (containing nothing).\n",
      "Hypothesis: You are in the art studio\n",
      "Entailment: 0.0004657926911022514\n",
      "Neutral: 0.9987221360206604\n",
      "Contradiction: 0.0008120540296658874\n",
      "----\n",
      "Premise: This room is called the art studio.\n",
      "Hypothesis: you see a large cupboard with its door closed\n",
      "Entailment: 0.0006529802922159433\n",
      "Neutral: 0.998615026473999\n",
      "Contradiction: 0.0007319457945413888\n",
      "----\n",
      "Premise: you see a large cupboard. The large cupboard door is closed.\n",
      "Hypothesis: you see a large cupboard with its door closed\n",
      "Entailment: 0.9915299415588379\n",
      "Neutral: 0.007830078713595867\n",
      "Contradiction: 0.0006399865378625691\n",
      "----\n",
      "Premise: you see a table. On the table is: a glass cup (containing nothing).\n",
      "Hypothesis: you see a large cupboard with its door closed\n",
      "Entailment: 0.0017020362429320812\n",
      "Neutral: 0.0760854110121727\n",
      "Contradiction: 0.9222126007080078\n",
      "----\n",
      "Premise: This room is called the art studio.\n",
      "Hypothesis: you see a table with a glass cup containing nothing\n",
      "Entailment: 0.0006658594938926399\n",
      "Neutral: 0.9951862692832947\n",
      "Contradiction: 0.0041478765197098255\n",
      "----\n",
      "Premise: you see a large cupboard. The large cupboard door is closed.\n",
      "Hypothesis: you see a table with a glass cup containing nothing\n",
      "Entailment: 0.001232507755048573\n",
      "Neutral: 0.9228984713554382\n",
      "Contradiction: 0.07586909085512161\n",
      "----\n",
      "Premise: you see a table. On the table is: a glass cup (containing nothing).\n",
      "Hypothesis: you see a table with a glass cup containing nothing\n",
      "Entailment: 0.9949937462806702\n",
      "Neutral: 0.004446764942258596\n",
      "Contradiction: 0.0005594845861196518\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tokenized_input_seq_pair = tokenizer.batch_encode_plus(a,\n",
    "                                                 max_length=max_length,\n",
    "                                                 return_token_type_ids=True, truncation=True, padding=True)\n",
    "\n",
    "input_ids = torch.tensor(tokenized_input_seq_pair['input_ids'], device=device).long()#.unsqueeze(0)\n",
    "# remember bart doesn't have 'token_type_ids', remove the line below if you are using bart.\n",
    "token_type_ids = torch.tensor(tokenized_input_seq_pair['token_type_ids'], device=device).long()#.unsqueeze(0)\n",
    "attention_mask = torch.tensor(tokenized_input_seq_pair['attention_mask'], device=device).long()#.unsqueeze(0)\n",
    "\n",
    "outputs = model(input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=None)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Inference time: {end - start}\")\n",
    "logits = outputs[0]\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "for i, pair in enumerate(a):\n",
    "    predicted_probability = probs[i].tolist()  # batch_size only one\n",
    "    print('----')\n",
    "    print(\"Premise:\", pair[0])\n",
    "    print(\"Hypothesis:\", pair[1])\n",
    "    print(\"Entailment:\", predicted_probability[int(config.label2id['entailment'])])\n",
    "    print(\"Neutral:\", predicted_probability[int(config.label2id['neutral'])])\n",
    "    print(\"Contradiction:\", predicted_probability[int(config.label2id['contradiction'])])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T16:01:34.661981Z",
     "end_time": "2023-07-10T16:01:35.259799Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- $context = (c_1, c_2)$\n",
    "- $beliefbase = (b_1, b_2)$\n",
    "- $(b_1 \\models c_1 \\lor b_2 \\models c_1) \\land (b_1 \\models c_2 \\lor b_2 \\models c_2)$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([1, 2, 2]), tensor([2, 1, 0]), tensor([2, 1, 0])]"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_context = len(context)\n",
    "num_beliefs = len(obs)\n",
    "\n",
    "argmax_probs = probs.argmax(-1)\n",
    "slice_idx = []\n",
    "idx = 0\n",
    "for i in range(num_context):\n",
    "    slice_idx.append(argmax_probs[idx:(idx + num_beliefs)])\n",
    "    idx = num_beliefs\n",
    "slice_idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T16:01:35.261813Z",
     "end_time": "2023-07-10T16:01:35.264831Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#c1_or = torch.where(c1 == entailment_idx, True, False)\n",
    "#c2_or = torch.where(c2 == entailment_idx, True, False)\n",
    "entailment_idx = 1\n",
    "context_or = [torch.where(c == entailment_idx, True, False).any().unsqueeze(0) for c in slice_idx]\n",
    "all_ors = torch.concatenate(context_or) # contiguous\n",
    "entailment = all_ors.all()\n",
    "if entailment:\n",
    "    print(entailment.item())\n",
    "else:\n",
    "    print(\"not entailment\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T16:02:38.686080Z",
     "end_time": "2023-07-10T16:02:38.741442Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([True, True, True])"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T16:02:52.016021Z",
     "end_time": "2023-07-10T16:02:52.021193Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.5057e-04, 8.9700e-01, 1.0275e-01],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n        [5.5948e-04, 9.9499e-01, 4.4468e-03]], grad_fn=<MulBackward0>)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment_mask = torch.where(argmax_probs == entailment_idx, True, False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T15:46:25.047902Z",
     "end_time": "2023-07-10T15:46:25.095308Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.9460, grad_fn=<MeanBackward0>)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment_probs = (probs[:, entailment_idx] * entailment_mask)\n",
    "entailment_probs[entailment_probs != 0].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T15:52:32.611493Z",
     "end_time": "2023-07-10T15:52:32.616407Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Tensor"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(entailment_probs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T15:56:26.398385Z",
     "end_time": "2023-07-10T15:56:26.407458Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
