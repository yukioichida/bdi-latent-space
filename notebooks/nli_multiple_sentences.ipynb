{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-08-24T18:34:16.679177Z",
     "end_time": "2023-08-24T18:34:18.044383Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import itertools\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model\n",
      "Combinations = 1\n",
      "{'entailment': 0, 'neutral': 1, 'contradiction': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded 36.25479698181152 - model cpu\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"Loading Model\")\n",
    "\n",
    "# AIMA -> explicar no contexto de busca\n",
    "obs = ['In your inventory, you see: a metal pot (containing a substance called caesium) an orange a thermometer, currently reading a temperature of 10 degrees celsius ']\n",
    "\n",
    "context = ['you have metal pot with caesium in your inventory']\n",
    "#\n",
    "\n",
    "a = list(itertools.product(obs, context))\n",
    "a.sort(key=lambda x: x[1])\n",
    "print(f\"Combinations = {len(a)}\")\n",
    "\n",
    "max_length = 256\n",
    "\n",
    "hg_model_hub_name = \"ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(hg_model_hub_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(hg_model_hub_name)\n",
    "\n",
    "print(config.label2id)\n",
    "\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(hg_model_hub_name)\n",
    "model.to(device)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Model loaded {end - start} - model {model.device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T16:40:13.874284Z",
     "end_time": "2023-08-25T16:40:50.268469Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 0.7378344535827637\n",
      "----\n",
      "Premise: In your inventory, you see: a metal pot (containing a substance called caesium) an orange a thermometer, currently reading a temperature of 10 degrees celsius \n",
      "Hypothesis: you have metal pot with caesium in your inventory\n",
      "Entailment: 0.990742027759552\n",
      "Neutral: 0.007689112797379494\n",
      "Contradiction: 0.0015688496641814709\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tokenized_input_seq_pair = tokenizer.batch_encode_plus(a,\n",
    "                                                       max_length=max_length,\n",
    "                                                       return_token_type_ids=True, truncation=True, padding=True)\n",
    "\n",
    "input_ids = torch.tensor(tokenized_input_seq_pair['input_ids'], device=device).long()  #.unsqueeze(0)\n",
    "# remember bart doesn't have 'token_type_ids', remove the line below if you are using bart.\n",
    "token_type_ids = torch.tensor(tokenized_input_seq_pair['token_type_ids'], device=device).long()  #.unsqueeze(0)\n",
    "attention_mask = torch.tensor(tokenized_input_seq_pair['attention_mask'], device=device).long()  #.unsqueeze(0)\n",
    "\n",
    "outputs = model(input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                labels=None)\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Inference time: {end - start}\")\n",
    "logits = outputs[0]\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "for i, pair in enumerate(a):\n",
    "    predicted_probability = probs[i].tolist()  # batch_size only one\n",
    "    print('----')\n",
    "    print(\"Premise:\", pair[0])\n",
    "    print(\"Hypothesis:\", pair[1])\n",
    "    print(\"Entailment:\", predicted_probability[int(config.label2id['entailment'])])\n",
    "    print(\"Neutral:\", predicted_probability[int(config.label2id['neutral'])])\n",
    "    print(\"Contradiction:\", predicted_probability[int(config.label2id['contradiction'])])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T16:40:50.285667Z",
     "end_time": "2023-08-25T16:40:51.210911Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- $context = (c_1, c_2)$\n",
    "- $beliefbase = (b_1, b_2)$\n",
    "- $(b_1 \\models c_1 \\lor b_2 \\models c_1) \\land (b_1 \\models c_2 \\lor b_2 \\models c_2)$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([0, 0]), tensor([1, 0])]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_context = len(context)\n",
    "num_beliefs = len(obs)\n",
    "\n",
    "argmax_probs = probs.argmax(-1)\n",
    "slice_idx = []\n",
    "idx = 0\n",
    "for i in range(num_context):\n",
    "    slice_idx.append(argmax_probs[idx:(idx + num_beliefs)])\n",
    "    idx = num_beliefs\n",
    "slice_idx"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T13:28:14.068613Z",
     "end_time": "2023-08-25T13:28:14.119817Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#c1_or = torch.where(c1 == entailment_idx, True, False)\n",
    "#c2_or = torch.where(c2 == entailment_idx, True, False)\n",
    "entailment_idx = 0\n",
    "context_or = [torch.where(c == entailment_idx, True, False).any().unsqueeze(0) for c in slice_idx]\n",
    "all_ors = torch.concatenate(context_or)  # contiguous\n",
    "entailment = all_ors.all()\n",
    "if entailment:\n",
    "    print(entailment.item())\n",
    "else:\n",
    "    print(\"not entailment\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T13:29:37.683657Z",
     "end_time": "2023-08-25T13:29:37.738656Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([True, True])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T13:29:39.247980Z",
     "end_time": "2023-08-25T13:29:39.261090Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([False]), tensor([True])]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_or"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-25T13:29:19.424024Z",
     "end_time": "2023-08-25T13:29:19.451012Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.9460, grad_fn=<MeanBackward0>)"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment_probs = (probs[:, entailment_idx] * entailment_mask)\n",
    "entailment_probs[entailment_probs != 0].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T15:52:32.611493Z",
     "end_time": "2023-07-10T15:52:32.616407Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Tensor"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(entailment_probs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-10T15:56:26.398385Z",
     "end_time": "2023-07-10T15:56:26.407458Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
