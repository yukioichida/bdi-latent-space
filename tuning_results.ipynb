{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['train_id', 'emb_dim', 'h_dim', 'latent_dim', 'categorical_dim',\n       'batch_size', 'save_model', 'initial_temp', 'min_temp', 'epochs',\n       'anneal_rate', 'activation', 'current_epoch', 'train_loss', 'kld',\n       'recon_loss'],\n      dtype='object')"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "result_df = pd.read_csv(\"train_results/tunning_results_XSNWJgpS.csv\")\n",
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "    emb_dim  h_dim  latent_dim  categorical_dim activation  train_loss\n21      200    300          15                2     gumbel   79.776806\n33      300    300          15                2     gumbel   79.835908\n23      200    300          30                2     gumbel   82.658283\n11      100    300          30                2     gumbel   82.669717\n35      300    300          30                2     gumbel   85.113064\n17      200    200          15                2     gumbel   86.621151\n19      200    200          30                2     gumbel   86.630435\n31      300    200          30                2     gumbel   87.724815\n22      200    300          30                2         bc   88.032241\n20      200    300          15                2         bc   88.966055\n32      300    300          15                2         bc   89.329384\n34      300    300          30                2         bc   90.347864\n29      300    200          15                2     gumbel   90.821010\n8       100    300          15                2         bc   91.293083\n9       100    300          15                2     gumbel   91.616220\n10      100    300          30                2         bc   91.750280\n5       100    200          15                2     gumbel   98.057307\n13      200    100          15                2     gumbel   98.143500\n6       100    200          30                2         bc   98.509749\n30      300    200          30                2         bc   98.825927\n18      200    200          30                2         bc   98.843076\n7       100    200          30                2     gumbel  100.008683\n4       100    200          15                2         bc  100.025058\n15      200    100          30                2     gumbel  100.176421\n16      200    200          15                2         bc  100.430670\n28      300    200          15                2         bc  100.542290\n27      300    100          30                2     gumbel  100.971007\n25      300    100          15                2     gumbel  103.418855\n3       100    100          30                2     gumbel  104.164662\n1       100    100          15                2     gumbel  106.513304\n26      300    100          30                2         bc  107.213424\n12      200    100          15                2         bc  107.796437\n0       100    100          15                2         bc  108.115089\n24      300    100          15                2         bc  108.137851\n14      200    100          30                2         bc  108.215341\n2       100    100          30                2         bc  108.236375",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emb_dim</th>\n      <th>h_dim</th>\n      <th>latent_dim</th>\n      <th>categorical_dim</th>\n      <th>activation</th>\n      <th>train_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21</th>\n      <td>200</td>\n      <td>300</td>\n      <td>15</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>79.776806</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>300</td>\n      <td>300</td>\n      <td>15</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>79.835908</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>82.658283</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>100</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>82.669717</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>300</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>85.113064</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>200</td>\n      <td>200</td>\n      <td>15</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>86.621151</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>200</td>\n      <td>200</td>\n      <td>30</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>86.630435</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>300</td>\n      <td>200</td>\n      <td>30</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>87.724815</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>88.032241</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>200</td>\n      <td>300</td>\n      <td>15</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>88.966055</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>300</td>\n      <td>300</td>\n      <td>15</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>89.329384</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>300</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>90.347864</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>300</td>\n      <td>200</td>\n      <td>15</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>90.821010</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>100</td>\n      <td>300</td>\n      <td>15</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>91.293083</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>100</td>\n      <td>300</td>\n      <td>15</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>91.616220</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>100</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>91.750280</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>100</td>\n      <td>200</td>\n      <td>15</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>98.057307</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>200</td>\n      <td>100</td>\n      <td>15</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>98.143500</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>100</td>\n      <td>200</td>\n      <td>30</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>98.509749</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>300</td>\n      <td>200</td>\n      <td>30</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>98.825927</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>200</td>\n      <td>200</td>\n      <td>30</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>98.843076</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>100</td>\n      <td>200</td>\n      <td>30</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>100.008683</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100</td>\n      <td>200</td>\n      <td>15</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>100.025058</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>200</td>\n      <td>100</td>\n      <td>30</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>100.176421</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>200</td>\n      <td>200</td>\n      <td>15</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>100.430670</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>300</td>\n      <td>200</td>\n      <td>15</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>100.542290</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>300</td>\n      <td>100</td>\n      <td>30</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>100.971007</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>300</td>\n      <td>100</td>\n      <td>15</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>103.418855</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100</td>\n      <td>100</td>\n      <td>30</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>104.164662</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100</td>\n      <td>100</td>\n      <td>15</td>\n      <td>2</td>\n      <td>gumbel</td>\n      <td>106.513304</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>300</td>\n      <td>100</td>\n      <td>30</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>107.213424</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>200</td>\n      <td>100</td>\n      <td>15</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>107.796437</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>100</td>\n      <td>100</td>\n      <td>15</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>108.115089</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>300</td>\n      <td>100</td>\n      <td>15</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>108.137851</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>200</td>\n      <td>100</td>\n      <td>30</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>108.215341</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100</td>\n      <td>100</td>\n      <td>30</td>\n      <td>2</td>\n      <td>bc</td>\n      <td>108.236375</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['emb_dim', 'h_dim', 'latent_dim', 'categorical_dim', 'activation']\n",
    "\n",
    "grouped_df = result_df.groupby(columns).agg({'train_loss': 'min'})\n",
    "grouped_df.reset_index().sort_values([\"train_loss\", \"latent_dim\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "        train_id  emb_dim  h_dim  latent_dim  categorical_dim  batch_size  \\\n1199  tunning_23      200    300          30                2         128   \n1198  tunning_23      200    300          30                2         128   \n1197  tunning_23      200    300          30                2         128   \n1196  tunning_23      200    300          30                2         128   \n1192  tunning_23      200    300          30                2         128   \n1191  tunning_23      200    300          30                2         128   \n1195  tunning_23      200    300          30                2         128   \n1190  tunning_23      200    300          30                2         128   \n1189  tunning_23      200    300          30                2         128   \n1188  tunning_23      200    300          30                2         128   \n1194  tunning_23      200    300          30                2         128   \n1187  tunning_23      200    300          30                2         128   \n1186  tunning_23      200    300          30                2         128   \n1185  tunning_23      200    300          30                2         128   \n1184  tunning_23      200    300          30                2         128   \n1183  tunning_23      200    300          30                2         128   \n1182  tunning_23      200    300          30                2         128   \n1181  tunning_23      200    300          30                2         128   \n1193  tunning_23      200    300          30                2         128   \n1180  tunning_23      200    300          30                2         128   \n1179  tunning_23      200    300          30                2         128   \n1178  tunning_23      200    300          30                2         128   \n1177  tunning_23      200    300          30                2         128   \n1176  tunning_23      200    300          30                2         128   \n1175  tunning_23      200    300          30                2         128   \n1173  tunning_23      200    300          30                2         128   \n1172  tunning_23      200    300          30                2         128   \n1174  tunning_23      200    300          30                2         128   \n1171  tunning_23      200    300          30                2         128   \n1169  tunning_23      200    300          30                2         128   \n1170  tunning_23      200    300          30                2         128   \n1167  tunning_23      200    300          30                2         128   \n1168  tunning_23      200    300          30                2         128   \n1166  tunning_23      200    300          30                2         128   \n1165  tunning_23      200    300          30                2         128   \n1164  tunning_23      200    300          30                2         128   \n1163  tunning_23      200    300          30                2         128   \n1162  tunning_23      200    300          30                2         128   \n1161  tunning_23      200    300          30                2         128   \n1160  tunning_23      200    300          30                2         128   \n1159  tunning_23      200    300          30                2         128   \n1158  tunning_23      200    300          30                2         128   \n1157  tunning_23      200    300          30                2         128   \n1156  tunning_23      200    300          30                2         128   \n1155  tunning_23      200    300          30                2         128   \n1154  tunning_23      200    300          30                2         128   \n1153  tunning_23      200    300          30                2         128   \n1152  tunning_23      200    300          30                2         128   \n1151  tunning_23      200    300          30                2         128   \n1150  tunning_23      200    300          30                2         128   \n\n      save_model  initial_temp  min_temp  epochs  anneal_rate activation  \\\n1199       False           1.0       0.5      50      0.00003         bc   \n1198       False           1.0       0.5      50      0.00003         bc   \n1197       False           1.0       0.5      50      0.00003         bc   \n1196       False           1.0       0.5      50      0.00003         bc   \n1192       False           1.0       0.5      50      0.00003         bc   \n1191       False           1.0       0.5      50      0.00003         bc   \n1195       False           1.0       0.5      50      0.00003         bc   \n1190       False           1.0       0.5      50      0.00003         bc   \n1189       False           1.0       0.5      50      0.00003         bc   \n1188       False           1.0       0.5      50      0.00003         bc   \n1194       False           1.0       0.5      50      0.00003         bc   \n1187       False           1.0       0.5      50      0.00003         bc   \n1186       False           1.0       0.5      50      0.00003         bc   \n1185       False           1.0       0.5      50      0.00003         bc   \n1184       False           1.0       0.5      50      0.00003         bc   \n1183       False           1.0       0.5      50      0.00003         bc   \n1182       False           1.0       0.5      50      0.00003         bc   \n1181       False           1.0       0.5      50      0.00003         bc   \n1193       False           1.0       0.5      50      0.00003         bc   \n1180       False           1.0       0.5      50      0.00003         bc   \n1179       False           1.0       0.5      50      0.00003         bc   \n1178       False           1.0       0.5      50      0.00003         bc   \n1177       False           1.0       0.5      50      0.00003         bc   \n1176       False           1.0       0.5      50      0.00003         bc   \n1175       False           1.0       0.5      50      0.00003         bc   \n1173       False           1.0       0.5      50      0.00003         bc   \n1172       False           1.0       0.5      50      0.00003         bc   \n1174       False           1.0       0.5      50      0.00003         bc   \n1171       False           1.0       0.5      50      0.00003         bc   \n1169       False           1.0       0.5      50      0.00003         bc   \n1170       False           1.0       0.5      50      0.00003         bc   \n1167       False           1.0       0.5      50      0.00003         bc   \n1168       False           1.0       0.5      50      0.00003         bc   \n1166       False           1.0       0.5      50      0.00003         bc   \n1165       False           1.0       0.5      50      0.00003         bc   \n1164       False           1.0       0.5      50      0.00003         bc   \n1163       False           1.0       0.5      50      0.00003         bc   \n1162       False           1.0       0.5      50      0.00003         bc   \n1161       False           1.0       0.5      50      0.00003         bc   \n1160       False           1.0       0.5      50      0.00003         bc   \n1159       False           1.0       0.5      50      0.00003         bc   \n1158       False           1.0       0.5      50      0.00003         bc   \n1157       False           1.0       0.5      50      0.00003         bc   \n1156       False           1.0       0.5      50      0.00003         bc   \n1155       False           1.0       0.5      50      0.00003         bc   \n1154       False           1.0       0.5      50      0.00003         bc   \n1153       False           1.0       0.5      50      0.00003         bc   \n1152       False           1.0       0.5      50      0.00003         bc   \n1151       False           1.0       0.5      50      0.00003         bc   \n1150       False           1.0       0.5      50      0.00003         bc   \n\n      current_epoch  train_loss       kld  recon_loss  \n1199             49   88.032241  0.002974   88.029268  \n1198             48   88.905895  0.002879   88.903016  \n1197             47   89.548766  0.003767   89.544999  \n1196             46   90.060182  0.003856   90.056326  \n1192             42   90.294300  0.001412   90.292888  \n1191             41   90.940507  0.001135   90.939372  \n1195             45   91.274193  0.004425   91.269767  \n1190             40   91.707661  0.001236   91.706424  \n1189             39   92.316889  0.001249   92.315640  \n1188             38   92.609841  0.001646   92.608194  \n1194             44   93.565604  0.006670   93.558934  \n1187             37   93.673705  0.001078   93.672627  \n1186             36   95.101893  0.001238   95.100655  \n1185             35   95.710972  0.001736   95.709235  \n1184             34   96.021445  0.001327   96.020117  \n1183             33   97.126197  0.001705   97.124492  \n1182             32   97.889468  0.002115   97.887353  \n1181             31   98.423268  0.003418   98.419849  \n1193             43   99.192528  1.315545   97.876983  \n1180             30   99.281820  0.001727   99.280093  \n1179             29  100.296121  0.001839  100.294282  \n1178             28  101.238771  0.001641  101.237130  \n1177             27  102.225880  0.001298  102.224582  \n1176             26  103.470942  0.001368  103.469574  \n1175             25  104.556351  0.001642  104.554708  \n1173             23  105.513519  0.003137  105.510382  \n1172             22  105.822333  0.001680  105.820653  \n1174             24  106.834366  0.002781  106.831586  \n1171             21  107.497189  0.002614  107.494575  \n1169             19  107.834370  0.010807  107.823563  \n1170             20  109.132812  0.028314  109.104498  \n1167             17  109.165235  0.021520  109.143715  \n1168             18  109.557183  0.016325  109.540858  \n1166             16  109.984876  0.023099  109.961777  \n1165             15  110.971461  0.019547  110.951914  \n1164             14  111.605911  0.038903  111.567008  \n1163             13  112.370822  0.066102  112.304720  \n1162             12  113.317925  0.026361  113.291564  \n1161             11  114.131234  0.037801  114.093433  \n1160             10  114.911131  0.054864  114.856267  \n1159              9  115.565192  0.036522  115.528670  \n1158              8  116.181653  0.009332  116.172321  \n1157              7  116.795971  0.030833  116.765138  \n1156              6  117.329200  0.013552  117.315648  \n1155              5  117.903612  0.037839  117.865773  \n1154              4  118.641162  0.009353  118.631809  \n1153              3  119.718902  0.019018  119.699883  \n1152              2  121.291453  0.015821  121.275632  \n1151              1  124.201688  0.016988  124.184700  \n1150              0  155.440558  0.248403  155.192155  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train_id</th>\n      <th>emb_dim</th>\n      <th>h_dim</th>\n      <th>latent_dim</th>\n      <th>categorical_dim</th>\n      <th>batch_size</th>\n      <th>save_model</th>\n      <th>initial_temp</th>\n      <th>min_temp</th>\n      <th>epochs</th>\n      <th>anneal_rate</th>\n      <th>activation</th>\n      <th>current_epoch</th>\n      <th>train_loss</th>\n      <th>kld</th>\n      <th>recon_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1199</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>49</td>\n      <td>88.032241</td>\n      <td>0.002974</td>\n      <td>88.029268</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>48</td>\n      <td>88.905895</td>\n      <td>0.002879</td>\n      <td>88.903016</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>47</td>\n      <td>89.548766</td>\n      <td>0.003767</td>\n      <td>89.544999</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>46</td>\n      <td>90.060182</td>\n      <td>0.003856</td>\n      <td>90.056326</td>\n    </tr>\n    <tr>\n      <th>1192</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>42</td>\n      <td>90.294300</td>\n      <td>0.001412</td>\n      <td>90.292888</td>\n    </tr>\n    <tr>\n      <th>1191</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>41</td>\n      <td>90.940507</td>\n      <td>0.001135</td>\n      <td>90.939372</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>45</td>\n      <td>91.274193</td>\n      <td>0.004425</td>\n      <td>91.269767</td>\n    </tr>\n    <tr>\n      <th>1190</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>40</td>\n      <td>91.707661</td>\n      <td>0.001236</td>\n      <td>91.706424</td>\n    </tr>\n    <tr>\n      <th>1189</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>39</td>\n      <td>92.316889</td>\n      <td>0.001249</td>\n      <td>92.315640</td>\n    </tr>\n    <tr>\n      <th>1188</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>38</td>\n      <td>92.609841</td>\n      <td>0.001646</td>\n      <td>92.608194</td>\n    </tr>\n    <tr>\n      <th>1194</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>44</td>\n      <td>93.565604</td>\n      <td>0.006670</td>\n      <td>93.558934</td>\n    </tr>\n    <tr>\n      <th>1187</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>37</td>\n      <td>93.673705</td>\n      <td>0.001078</td>\n      <td>93.672627</td>\n    </tr>\n    <tr>\n      <th>1186</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>36</td>\n      <td>95.101893</td>\n      <td>0.001238</td>\n      <td>95.100655</td>\n    </tr>\n    <tr>\n      <th>1185</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>35</td>\n      <td>95.710972</td>\n      <td>0.001736</td>\n      <td>95.709235</td>\n    </tr>\n    <tr>\n      <th>1184</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>34</td>\n      <td>96.021445</td>\n      <td>0.001327</td>\n      <td>96.020117</td>\n    </tr>\n    <tr>\n      <th>1183</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>33</td>\n      <td>97.126197</td>\n      <td>0.001705</td>\n      <td>97.124492</td>\n    </tr>\n    <tr>\n      <th>1182</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>32</td>\n      <td>97.889468</td>\n      <td>0.002115</td>\n      <td>97.887353</td>\n    </tr>\n    <tr>\n      <th>1181</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>31</td>\n      <td>98.423268</td>\n      <td>0.003418</td>\n      <td>98.419849</td>\n    </tr>\n    <tr>\n      <th>1193</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>43</td>\n      <td>99.192528</td>\n      <td>1.315545</td>\n      <td>97.876983</td>\n    </tr>\n    <tr>\n      <th>1180</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>30</td>\n      <td>99.281820</td>\n      <td>0.001727</td>\n      <td>99.280093</td>\n    </tr>\n    <tr>\n      <th>1179</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>29</td>\n      <td>100.296121</td>\n      <td>0.001839</td>\n      <td>100.294282</td>\n    </tr>\n    <tr>\n      <th>1178</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>28</td>\n      <td>101.238771</td>\n      <td>0.001641</td>\n      <td>101.237130</td>\n    </tr>\n    <tr>\n      <th>1177</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>27</td>\n      <td>102.225880</td>\n      <td>0.001298</td>\n      <td>102.224582</td>\n    </tr>\n    <tr>\n      <th>1176</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>26</td>\n      <td>103.470942</td>\n      <td>0.001368</td>\n      <td>103.469574</td>\n    </tr>\n    <tr>\n      <th>1175</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>25</td>\n      <td>104.556351</td>\n      <td>0.001642</td>\n      <td>104.554708</td>\n    </tr>\n    <tr>\n      <th>1173</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>23</td>\n      <td>105.513519</td>\n      <td>0.003137</td>\n      <td>105.510382</td>\n    </tr>\n    <tr>\n      <th>1172</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>22</td>\n      <td>105.822333</td>\n      <td>0.001680</td>\n      <td>105.820653</td>\n    </tr>\n    <tr>\n      <th>1174</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>24</td>\n      <td>106.834366</td>\n      <td>0.002781</td>\n      <td>106.831586</td>\n    </tr>\n    <tr>\n      <th>1171</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>21</td>\n      <td>107.497189</td>\n      <td>0.002614</td>\n      <td>107.494575</td>\n    </tr>\n    <tr>\n      <th>1169</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>19</td>\n      <td>107.834370</td>\n      <td>0.010807</td>\n      <td>107.823563</td>\n    </tr>\n    <tr>\n      <th>1170</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>20</td>\n      <td>109.132812</td>\n      <td>0.028314</td>\n      <td>109.104498</td>\n    </tr>\n    <tr>\n      <th>1167</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>17</td>\n      <td>109.165235</td>\n      <td>0.021520</td>\n      <td>109.143715</td>\n    </tr>\n    <tr>\n      <th>1168</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>18</td>\n      <td>109.557183</td>\n      <td>0.016325</td>\n      <td>109.540858</td>\n    </tr>\n    <tr>\n      <th>1166</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>16</td>\n      <td>109.984876</td>\n      <td>0.023099</td>\n      <td>109.961777</td>\n    </tr>\n    <tr>\n      <th>1165</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>15</td>\n      <td>110.971461</td>\n      <td>0.019547</td>\n      <td>110.951914</td>\n    </tr>\n    <tr>\n      <th>1164</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>14</td>\n      <td>111.605911</td>\n      <td>0.038903</td>\n      <td>111.567008</td>\n    </tr>\n    <tr>\n      <th>1163</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>13</td>\n      <td>112.370822</td>\n      <td>0.066102</td>\n      <td>112.304720</td>\n    </tr>\n    <tr>\n      <th>1162</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>12</td>\n      <td>113.317925</td>\n      <td>0.026361</td>\n      <td>113.291564</td>\n    </tr>\n    <tr>\n      <th>1161</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>11</td>\n      <td>114.131234</td>\n      <td>0.037801</td>\n      <td>114.093433</td>\n    </tr>\n    <tr>\n      <th>1160</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>10</td>\n      <td>114.911131</td>\n      <td>0.054864</td>\n      <td>114.856267</td>\n    </tr>\n    <tr>\n      <th>1159</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>9</td>\n      <td>115.565192</td>\n      <td>0.036522</td>\n      <td>115.528670</td>\n    </tr>\n    <tr>\n      <th>1158</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>8</td>\n      <td>116.181653</td>\n      <td>0.009332</td>\n      <td>116.172321</td>\n    </tr>\n    <tr>\n      <th>1157</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>7</td>\n      <td>116.795971</td>\n      <td>0.030833</td>\n      <td>116.765138</td>\n    </tr>\n    <tr>\n      <th>1156</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>6</td>\n      <td>117.329200</td>\n      <td>0.013552</td>\n      <td>117.315648</td>\n    </tr>\n    <tr>\n      <th>1155</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>5</td>\n      <td>117.903612</td>\n      <td>0.037839</td>\n      <td>117.865773</td>\n    </tr>\n    <tr>\n      <th>1154</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>4</td>\n      <td>118.641162</td>\n      <td>0.009353</td>\n      <td>118.631809</td>\n    </tr>\n    <tr>\n      <th>1153</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>3</td>\n      <td>119.718902</td>\n      <td>0.019018</td>\n      <td>119.699883</td>\n    </tr>\n    <tr>\n      <th>1152</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>2</td>\n      <td>121.291453</td>\n      <td>0.015821</td>\n      <td>121.275632</td>\n    </tr>\n    <tr>\n      <th>1151</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>1</td>\n      <td>124.201688</td>\n      <td>0.016988</td>\n      <td>124.184700</td>\n    </tr>\n    <tr>\n      <th>1150</th>\n      <td>tunning_23</td>\n      <td>200</td>\n      <td>300</td>\n      <td>30</td>\n      <td>2</td>\n      <td>128</td>\n      <td>False</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>50</td>\n      <td>0.00003</td>\n      <td>bc</td>\n      <td>0</td>\n      <td>155.440558</td>\n      <td>0.248403</td>\n      <td>155.192155</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[(result_df['emb_dim'] == 200) & (result_df['h_dim'] == 300) & (result_df['activation'] == 'bc') & (result_df['latent_dim'] == 30)].sort_values(\"train_loss\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
